{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kacyp\\OneDrive\\Pulpit\\repo\\gauss-show\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from embetter.grab import ColumnGrabber\n",
    "from embetter.multi import ClipEncoder\n",
    "from embetter.text import SentenceEncoder\n",
    "from embetter.vision import ImageLoader\n",
    "from sklearn.linear_model import (LogisticRegression, Perceptron,\n",
    "                                  QuantileRegressor)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rura_img = make_pipeline(\n",
    "    ImageLoader(convert=\"RGB\"),\n",
    "    ClipEncoder(),\n",
    ")\n",
    "\n",
    "rura_text = make_pipeline(\n",
    "    ColumnGrabber(\"text\"),\n",
    "    SentenceEncoder()\n",
    ")\n",
    "rura_text2 = make_pipeline(\n",
    "    ColumnGrabber(\"Text\"),\n",
    "    SentenceEncoder()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_pets = []\n",
    "labels_pets = []\n",
    "\n",
    "paths_cats = []\n",
    "labels_cats = []\n",
    "\n",
    "\n",
    "\n",
    "for path in Path(\"pets\").glob(\"*.jpg\"):\n",
    "    stem = path.stem\n",
    "    paths_pets.append(str(path))\n",
    "    labels_pets.append(stem[:stem.rfind(\"_\")])\n",
    "\n",
    "for path in Path(\"kotki\").iterdir():\n",
    "    for sub_path in Path(path).glob('*.jpg'):\n",
    "        labels_cats.append(sub_path.parent.name)\n",
    "        paths_cats.append(str(sub_path))\n",
    "\n",
    "\n",
    "#DLACZEGO DATASETY NA KAGGLE'U SA ZJEBANE?\n",
    "\n",
    "df = pd.read_csv('twitter_training.csv')\n",
    "df.columns = ['id', 'entity', 'sentiment', 'text']\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['entity'] = df['entity'].astype('string')\n",
    "df['sentiment'] = df['sentiment'].astype('string')\n",
    "df['text'] = df['text'].astype('string')\n",
    "\n",
    "df2 = pd.read_csv('dataset.csv')\n",
    "df2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n"
     ]
    }
   ],
   "source": [
    "# X_1 = rura_img.transform(paths_pets)\n",
    "# X_2 = rura_img.transform(paths_cats)\n",
    "\n",
    "# X_3 = rura_text.transform(df[:len(df)//2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_4 = rura_text2.transform(df2)\n",
    "\n",
    "X_1, X_2, X_3, X_4 = joblib.load('super-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03038803, -0.4069671 ,  0.22537117, ...,  0.30013418,\n",
       "        -0.49421257, -0.3539784 ],\n",
       "       [ 0.22172228,  0.10130153,  0.27347124, ...,  0.76611614,\n",
       "        -0.3093354 , -0.04325171],\n",
       "       [ 0.1225246 , -0.332682  ,  0.12871505, ...,  0.13546167,\n",
       "        -0.44622442, -0.33025128],\n",
       "       ...,\n",
       "       [-0.01610568, -0.24678226, -0.14172104, ...,  0.8317056 ,\n",
       "         0.09846329, -0.07646413],\n",
       "       [ 0.2540474 ,  0.13698183, -0.06307959, ...,  0.7262149 ,\n",
       "         0.10655477,  0.18177734],\n",
       "       [-0.04472077,  0.16235577, -0.17671788, ...,  0.89453113,\n",
       "         0.2877938 , -0.03816501]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LogisticRegression(max_iter=1000)\n",
    "model_2 = Perceptron()\n",
    "model_3 = QuantileRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.86, 0.842],\n",
       " [0.861277072442121, 0.8381067961165047],\n",
       " [0.5009589937281517, 0.38957066879015795],\n",
       " [0.9644999999999999, 0.9543636363636365])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_1 = [np.mean(cross_val_score(model_1, X_1, labels_pets, cv=5)), \n",
    "         np.mean(cross_val_score(model_2, X_1, labels_pets, cv=5)), \n",
    "        #  np.mean(cross_val_score(model_3, X_1, labels_pets, cv=5))\n",
    "         ]\n",
    "\n",
    "\n",
    "means_2 = [np.mean(cross_val_score(model_1, X_2, labels_cats, cv=5)), \n",
    "         np.mean(cross_val_score(model_2, X_2, labels_cats, cv=5)), \n",
    "        #  np.mean(cross_val_score(model_3, X_2, labels_cats, cv=5))\n",
    "         ]\n",
    "\n",
    "means_3 = [np.mean(cross_val_score(model_1, X_3, df[:len(df)//2]['sentiment'], cv=5)), \n",
    "         np.mean(cross_val_score(model_2, X_3, df[:len(df)//2]['sentiment'], cv=5)), \n",
    "        #  np.mean(cross_val_score(model_3, X_2, labels_cats, cv=5))\n",
    "         ]\n",
    "\n",
    "means_4 = [np.mean(cross_val_score(model_1, X_4, df2['language'], cv=5)), \n",
    "         np.mean(cross_val_score(model_2, X_4, df2['language'], cv=5)), \n",
    "        #  np.mean(cross_val_score(model_3, X_2, labels_cats, cv=5))\n",
    "         ]\n",
    "\n",
    "\n",
    "(means_1, means_2, means_3, means_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['super-data.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((X_4, df2['language']), 'data.pkl')\n",
    "joblib.dump((X_1, X_2, X_3, X_4), 'super-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_4, df2['language'])\n",
    "model_1.predict(make_pipeline(SentenceEncoder()).transform('Quick Brown Fox').reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
