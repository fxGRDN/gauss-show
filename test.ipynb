{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from embetter.grab import ColumnGrabber\n",
    "from embetter.multi import ClipEncoder\n",
    "from embetter.text import SentenceEncoder\n",
    "from embetter.vision import ImageLoader\n",
    "from sklearn.linear_model import (LogisticRegression, Perceptron,\n",
    "                                  QuantileRegressor)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rura_img = make_pipeline(\n",
    "    ImageLoader(convert=\"RGB\"),\n",
    "    ClipEncoder(),\n",
    ")\n",
    "\n",
    "rura_text = make_pipeline(\n",
    "    ColumnGrabber(\"text\"),\n",
    "    SentenceEncoder()\n",
    ")\n",
    "rura_text2 = make_pipeline(\n",
    "    ColumnGrabber(\"Text\"),\n",
    "    SentenceEncoder()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        klement gottwaldi surnukeha palsameeriti ning ...\n",
       "1        sebes joseph pereira thomas  på eng the jesuit...\n",
       "2        ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...\n",
       "3        விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...\n",
       "4        de spons behoort tot het geslacht haliclona en...\n",
       "                               ...                        \n",
       "21995    hors du terrain les années  et  sont des année...\n",
       "21996    ใน พศ  หลักจากที่เสด็จประพาสแหลมมลายู ชวา อินเ...\n",
       "21997    con motivo de la celebración del septuagésimoq...\n",
       "21998    年月，當時還只有歲的她在美國出道，以mai-k名義推出首張英文《baby i like》，由...\n",
       "21999     aprilie sonda spațială messenger a nasa și-a ...\n",
       "Name: Text, Length: 22000, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_pets = []\n",
    "labels_pets = []\n",
    "\n",
    "paths_cats = []\n",
    "labels_cats = []\n",
    "\n",
    "\n",
    "\n",
    "for path in Path(\"pets\").glob(\"*.jpg\"):\n",
    "    stem = path.stem\n",
    "    paths_pets.append(str(path))\n",
    "    labels_pets.append(stem[:stem.rfind(\"_\")])\n",
    "\n",
    "for path in Path(\"kotki\").iterdir():\n",
    "    for sub_path in Path(path).glob('*.jpg'):\n",
    "        labels_cats.append(sub_path.parent.name)\n",
    "        paths_cats.append(str(sub_path))\n",
    "\n",
    "\n",
    "#DLACZEGO DATASETY NA KAGGLE'U SA ZJEBANE?\n",
    "\n",
    "df = pd.read_csv('twitter_training.csv')\n",
    "df.columns = ['id', 'entity', 'sentiment', 'text']\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['entity'] = df['entity'].astype('string')\n",
    "df['sentiment'] = df['sentiment'].astype('string')\n",
    "df['text'] = df['text'].astype('string')\n",
    "\n",
    "df2 = pd.read_csv('dataset.csv')\n",
    "df2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n",
      "Unused or unrecognized kwargs: padding.\n"
     ]
    }
   ],
   "source": [
    "X_1 = rura_img.transform(paths_pets)\n",
    "X_2 = rura_img.transform(paths_cats)\n",
    "\n",
    "X_3 = rura_text.transform(df[:len(df)//2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4 = rura_text2.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03038803, -0.4069671 ,  0.22537117, ...,  0.30013418,\n",
       "        -0.49421257, -0.3539784 ],\n",
       "       [ 0.22172228,  0.10130153,  0.27347124, ...,  0.76611614,\n",
       "        -0.3093354 , -0.04325171],\n",
       "       [ 0.1225246 , -0.332682  ,  0.12871505, ...,  0.13546167,\n",
       "        -0.44622442, -0.33025128],\n",
       "       ...,\n",
       "       [-0.01610568, -0.24678226, -0.14172104, ...,  0.8317056 ,\n",
       "         0.09846329, -0.07646413],\n",
       "       [ 0.2540474 ,  0.13698183, -0.06307959, ...,  0.7262149 ,\n",
       "         0.10655477,  0.18177734],\n",
       "       [-0.04472077,  0.16235577, -0.17671788, ...,  0.89453113,\n",
       "         0.2877938 , -0.03816501]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LogisticRegression(max_iter=1000)\n",
    "model_2 = Perceptron()\n",
    "model_3 = QuantileRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.86, 0.842],\n",
       " [0.861277072442121, 0.8381067961165047],\n",
       " [0.5009589937281517, 0.38957066879015795],\n",
       " [0.9644999999999999, 0.9543636363636365])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_1 = [np.mean(cross_val_score(model_1, X_1, labels_pets, cv=5)), \n",
    "         np.mean(cross_val_score(model_2, X_1, labels_pets, cv=5)), \n",
    "        #  np.mean(cross_val_score(model_3, X_1, labels_pets, cv=5))\n",
    "         ]\n",
    "\n",
    "\n",
    "means_2 = [np.mean(cross_val_score(model_1, X_2, labels_cats, cv=5)), \n",
    "         np.mean(cross_val_score(model_2, X_2, labels_cats, cv=5)), \n",
    "        #  np.mean(cross_val_score(model_3, X_2, labels_cats, cv=5))\n",
    "         ]\n",
    "\n",
    "means_3 = [np.mean(cross_val_score(model_1, X_3, df[:len(df)//2]['sentiment'], cv=5)), \n",
    "         np.mean(cross_val_score(model_2, X_3, df[:len(df)//2]['sentiment'], cv=5)), \n",
    "        #  np.mean(cross_val_score(model_3, X_2, labels_cats, cv=5))\n",
    "         ]\n",
    "\n",
    "means_4 = [np.mean(cross_val_score(model_1, X_4, df2['language'], cv=5)), \n",
    "         np.mean(cross_val_score(model_2, X_4, df2['language'], cv=5)), \n",
    "        #  np.mean(cross_val_score(model_3, X_2, labels_cats, cv=5))\n",
    "         ]\n",
    "\n",
    "\n",
    "(means_1, means_2, means_3, means_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
